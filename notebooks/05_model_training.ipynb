{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac1e3326-e8f8-477a-a9af-2a4ab9de222b",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "**Objective:** Build and train machine learning models to predict employee attrition\n",
    "\n",
    "**Models We'll Build:**\n",
    "1. **Logistic Regression** - Baseline linear model\n",
    "2. **Random Forest** - Advanced tree-based model\n",
    "\n",
    "**Evaluation Metrics:**\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1-Score\n",
    "- ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7deb2cb7-1750-47f9-a6f3-b95c2a77b350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, classification_report\n",
    ")\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bfee900-6c2f-42b4-bd66-3376c3ea24c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ML-ready dataset...\n",
      "Data loaded!\n",
      "Shape: (1470, 59)\n"
     ]
    }
   ],
   "source": [
    "# Load ML-ready data\n",
    "print(\"Loading ML-ready dataset...\")\n",
    "\n",
    "df = pd.read_csv('../data/processed/ml_ready_data.csv')\n",
    "\n",
    "print(f\"Data loaded!\")\n",
    "print(f\"Shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22574f10-918c-43ee-90e3-f60bb2f69222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing features and target variable...\n",
      "Total columns: 59\n",
      "\n",
      "Column types:\n",
      "int64      30\n",
      "bool       19\n",
      "object      7\n",
      "float64     3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Categorical text columns found: 7\n",
      "['Attrition', 'Gender', 'OverTime', 'TenureGroup', 'SalaryBin', 'AgeGroup', 'DistanceCategory']\n",
      "\n",
      "Total columns to exclude: 9\n",
      "\n",
      "Features prepared!\n",
      "  Feature columns: 31\n",
      "  Training samples: 1470\n",
      "\n",
      "Target distribution:\n",
      "Attrition_Binary\n",
      "0    1233\n",
      "1     237\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Attrition rate: 16.12%\n",
      "\n",
      "Features being used for modeling:\n",
      "    1. Age\n",
      "    2. DailyRate\n",
      "    3. DistanceFromHome\n",
      "    4. Education\n",
      "    5. EnvironmentSatisfaction\n",
      "    6. HourlyRate\n",
      "    7. JobInvolvement\n",
      "    8. JobLevel\n",
      "    9. JobSatisfaction\n",
      "   10. MonthlyIncome\n",
      "   11. MonthlyRate\n",
      "   12. NumCompaniesWorked\n",
      "   13. PercentSalaryHike\n",
      "   14. PerformanceRating\n",
      "   15. RelationshipSatisfaction\n",
      "   16. StockOptionLevel\n",
      "   17. TotalWorkingYears\n",
      "   18. TrainingTimesLastYear\n",
      "   19. WorkLifeBalance\n",
      "   20. YearsAtCompany\n",
      "   21. YearsInCurrentRole\n",
      "   22. YearsSinceLastPromotion\n",
      "   23. YearsWithCurrManager\n",
      "   24. Income_Age_Ratio\n",
      "   25. OverTime_Numeric\n",
      "   26. WLB_Index\n",
      "   27. TotalSatisfaction\n",
      "   28. YearsSincePromotion_Ratio\n",
      "   29. DeptRiskScore\n",
      "   30. OverTime_Binary\n",
      "   31. Gender_Binary\n"
     ]
    }
   ],
   "source": [
    "# Prepare features and target\n",
    "print(\"\\nPreparing features and target variable...\")\n",
    "\n",
    "# Target variable\n",
    "target = 'Attrition_Binary'\n",
    "\n",
    "# First, check what columns we have\n",
    "print(f\"Total columns: {len(df.columns)}\")\n",
    "print(\"\\nColumn types:\")\n",
    "print(df.dtypes.value_counts())\n",
    "\n",
    "# Identify categorical columns that need to be excluded\n",
    "categorical_text_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "print(f\"\\nCategorical text columns found: {len(categorical_text_cols)}\")\n",
    "print(categorical_text_cols)\n",
    "\n",
    "# Columns to exclude from features\n",
    "exclude_cols = [\n",
    "    'EmployeeNumber',      # ID column\n",
    "    'Attrition',           # Original categorical target\n",
    "    'Attrition_Binary',    # Target variable\n",
    "    'TenureGroup',         # Categorical (we'll use YearsAtCompany instead)\n",
    "    'SalaryBin',           # Categorical (we have MonthlyIncome)\n",
    "    'AgeGroup',            # Categorical (we have Age)\n",
    "    'DistanceCategory'     # Categorical (we have DistanceFromHome)\n",
    "] + categorical_text_cols  # Add ALL remaining text columns\n",
    "\n",
    "# Remove duplicates\n",
    "exclude_cols = list(set(exclude_cols))\n",
    "\n",
    "print(f\"\\nTotal columns to exclude: {len(exclude_cols)}\")\n",
    "\n",
    "# Create feature matrix X and target y\n",
    "X = df.drop(columns=exclude_cols, errors='ignore')\n",
    "y = df[target]\n",
    "\n",
    "# Make sure X only has numeric columns\n",
    "X = X.select_dtypes(include=[np.number])\n",
    "\n",
    "print(f\"\\nFeatures prepared!\")\n",
    "print(f\"  Feature columns: {X.shape[1]}\")\n",
    "print(f\"  Training samples: {X.shape[0]}\")\n",
    "\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(y.value_counts())\n",
    "print(f\"\\nAttrition rate: {y.mean()*100:.2f}%\")\n",
    "\n",
    "# Show feature names\n",
    "print(f\"\\nFeatures being used for modeling:\")\n",
    "for i, col in enumerate(X.columns, 1):\n",
    "    print(f\"   {i:2d}. {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6876f58c-cc56-4fef-b4e5-0df27025020d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking for missing values...\n",
      "No missing values found!\n"
     ]
    }
   ],
   "source": [
    "# Check for any remaining missing values\n",
    "print(\"\\nChecking for missing values...\")\n",
    "\n",
    "missing = X.isnull().sum()\n",
    "if missing.sum() > 0:\n",
    "    print(\"Found missing values:\")\n",
    "    print(missing[missing > 0])\n",
    "    # Fill with median\n",
    "    X = X.fillna(X.median())\n",
    "    print(\"âœ“ Filled with median\")\n",
    "else:\n",
    "    print(\"No missing values found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f9b0c47-8923-4483-a237-3a53202f541f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Splitting data into train and test sets...\n",
      "Data split complete!\n",
      "  Training set: 1176 samples (80.0%)\n",
      "  Test set: 294 samples (20.0%)\n",
      "\n",
      "Class distribution in train set:\n",
      "Attrition_Binary\n",
      "0    0.838435\n",
      "1    0.161565\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Train-test split\n",
    "print(\"\\nSplitting data into train and test sets...\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,      # 20% for testing\n",
    "    random_state=42,     # For reproducibility\n",
    "    stratify=y          # Maintain class distribution\n",
    ")\n",
    "\n",
    "print(f\"Data split complete!\")\n",
    "print(f\"  Training set: {X_train.shape[0]} samples ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"  Test set: {X_test.shape[0]} samples ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nClass distribution in train set:\")\n",
    "print(y_train.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157147c0-193e-4c3b-8290-438ed20e66bb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## MODEL 1: Logistic Regression\n",
    "\n",
    "**Why Logistic Regression?**\n",
    "- Simple, fast, interpretable\n",
    "- Good baseline model\n",
    "- Works well with scaled features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "380b7e2b-a040-4f10-a517-b3cab7a09d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling features for Logistic Regression...\n",
      "Features scaled and scaler saved!\n"
     ]
    }
   ],
   "source": [
    "# Feature scaling (important for Logistic Regression)\n",
    "print(\"Scaling features for Logistic Regression...\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Save scaler for future use\n",
    "joblib.dump(scaler, '../models/scaler.pkl')\n",
    "\n",
    "print(\"Features scaled and scaler saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c424ea55-3d51-487f-badc-d92b73980ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TRAINING MODEL 1: LOGISTIC REGRESSION\n",
      "======================================================================\n",
      "\n",
      "Training model...\n",
      "Logistic Regression trained successfully!\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING MODEL 1: LOGISTIC REGRESSION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "lr_model = LogisticRegression(\n",
    "    random_state=42,\n",
    "    max_iter=1000,\n",
    "    class_weight='balanced'  # Handle class imbalance\n",
    ")\n",
    "\n",
    "print(\"\\nTraining model...\")\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Logistic Regression trained successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70a6d698-17b5-4d40-9718-965dd997b2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Making predictions...\n",
      "Predictions complete!\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "print(\"\\nMaking predictions...\")\n",
    "\n",
    "y_pred_lr = lr_model.predict(X_test_scaled)\n",
    "y_pred_proba_lr = lr_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"Predictions complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d254df9d-9b5b-42fd-b322-ab1bb8090982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOGISTIC REGRESSION PERFORMANCE\n",
      "======================================================================\n",
      "Accuracy:  0.7415 (74.15%)\n",
      "Precision: 0.3505 (35.05%)\n",
      "Recall:    0.7234 (72.34%)\n",
      "F1-Score:  0.4722\n",
      "ROC-AUC:   0.7997\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Stayed       0.93      0.74      0.83       247\n",
      "        Left       0.35      0.72      0.47        47\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.64      0.73      0.65       294\n",
      "weighted avg       0.84      0.74      0.77       294\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Logistic Regression\n",
    "print(\"\\nLOGISTIC REGRESSION PERFORMANCE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "lr_accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "lr_precision = precision_score(y_test, y_pred_lr)\n",
    "lr_recall = recall_score(y_test, y_pred_lr)\n",
    "lr_f1 = f1_score(y_test, y_pred_lr)\n",
    "lr_roc_auc = roc_auc_score(y_test, y_pred_proba_lr)\n",
    "\n",
    "print(f\"Accuracy:  {lr_accuracy:.4f} ({lr_accuracy*100:.2f}%)\")\n",
    "print(f\"Precision: {lr_precision:.4f} ({lr_precision*100:.2f}%)\")\n",
    "print(f\"Recall:    {lr_recall:.4f} ({lr_recall*100:.2f}%)\")\n",
    "print(f\"F1-Score:  {lr_f1:.4f}\")\n",
    "print(f\"ROC-AUC:   {lr_roc_auc:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_lr, target_names=['Stayed', 'Left']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "980a9a51-d05e-447a-9950-a1aef7fc19ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation (5-Fold)...\n",
      "Cross-validation ROC-AUC scores: [0.67995747 0.83449105 0.82006412 0.81138124 0.86254341]\n",
      "Mean CV ROC-AUC: 0.8017 (+/- 0.0633)\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation for Logistic Regression\n",
    "print(\"\\nCross-Validation (5-Fold)...\")\n",
    "\n",
    "lr_cv_scores = cross_val_score(\n",
    "    lr_model, X_train_scaled, y_train,\n",
    "    cv=5, scoring='roc_auc'\n",
    ")\n",
    "\n",
    "print(f\"Cross-validation ROC-AUC scores: {lr_cv_scores}\")\n",
    "print(f\"Mean CV ROC-AUC: {lr_cv_scores.mean():.4f} (+/- {lr_cv_scores.std():.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afa3ae1e-3cf7-4a07-8ee6-bfb56f5413f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression model saved: models/logistic_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save Logistic Regression model\n",
    "joblib.dump(lr_model, '../models/logistic_model.pkl')\n",
    "print(\"\\nLogistic Regression model saved: models/logistic_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b63c2a-8103-4d9e-a9bc-83a10e317a7f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## MODEL 2: Random Forest\n",
    "\n",
    "**Why Random Forest?**\n",
    "- Handles non-linear relationships\n",
    "- Provides feature importance\n",
    "- Generally higher accuracy\n",
    "- No need for feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8cc4b068-005c-41fa-9a80-9c9896c374e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TRAINING MODEL 2: RANDOM FOREST\n",
      "======================================================================\n",
      "\n",
      "Training Random Forest (this may take 30-60 seconds)...\n",
      "Random Forest trained successfully!\n"
     ]
    }
   ],
   "source": [
    "# Train Random Forest\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING MODEL 2: RANDOM FOREST\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,        # Number of trees\n",
    "    max_depth=10,            # Prevent overfitting\n",
    "    min_samples_split=20,    # Minimum samples to split\n",
    "    min_samples_leaf=10,     # Minimum samples in leaf\n",
    "    random_state=42,\n",
    "    class_weight='balanced', # Handle imbalance\n",
    "    n_jobs=-1                # Use all CPU cores\n",
    ")\n",
    "\n",
    "print(\"\\nTraining Random Forest (this may take 30-60 seconds)...\")\n",
    "rf_model.fit(X_train, y_train)  # No scaling needed for trees!\n",
    "\n",
    "print(\"Random Forest trained successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4cb1c6a-e3b5-4906-b541-087c00513fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Making predictions...\n",
      "Predictions complete!\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "print(\"\\nMaking predictions...\")\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "y_pred_proba_rf = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Predictions complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b6a0474-f351-4267-8dcc-39a11facebc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RANDOM FOREST PERFORMANCE\n",
      "======================================================================\n",
      "Accuracy:  0.8231 (82.31%)\n",
      "Precision: 0.4545 (45.45%)\n",
      "Recall:    0.5319 (53.19%)\n",
      "F1-Score:  0.4902\n",
      "ROC-AUC:   0.7804\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Stayed       0.91      0.88      0.89       247\n",
      "        Left       0.45      0.53      0.49        47\n",
      "\n",
      "    accuracy                           0.82       294\n",
      "   macro avg       0.68      0.71      0.69       294\n",
      "weighted avg       0.84      0.82      0.83       294\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Random Forest\n",
    "print(\"\\nRANDOM FOREST PERFORMANCE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "rf_precision = precision_score(y_test, y_pred_rf)\n",
    "rf_recall = recall_score(y_test, y_pred_rf)\n",
    "rf_f1 = f1_score(y_test, y_pred_rf)\n",
    "rf_roc_auc = roc_auc_score(y_test, y_pred_proba_rf)\n",
    "\n",
    "print(f\"Accuracy:  {rf_accuracy:.4f} ({rf_accuracy*100:.2f}%)\")\n",
    "print(f\"Precision: {rf_precision:.4f} ({rf_precision*100:.2f}%)\")\n",
    "print(f\"Recall:    {rf_recall:.4f} ({rf_recall*100:.2f}%)\")\n",
    "print(f\"F1-Score:  {rf_f1:.4f}\")\n",
    "print(f\"ROC-AUC:   {rf_roc_auc:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf, target_names=['Stayed', 'Left']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75e9bcd3-3915-44d9-aa02-5ae80fba2700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation (5-Fold)...\n",
      "Cross-validation ROC-AUC scores: [0.67450824 0.8371627  0.80977825 0.75514293 0.82433877]\n",
      "Mean CV ROC-AUC: 0.7802 (+/- 0.0598)\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation for Random Forest\n",
    "print(\"\\nCross-Validation (5-Fold)...\")\n",
    "\n",
    "rf_cv_scores = cross_val_score(\n",
    "    rf_model, X_train, y_train,\n",
    "    cv=5, scoring='roc_auc'\n",
    ")\n",
    "\n",
    "print(f\"Cross-validation ROC-AUC scores: {rf_cv_scores}\")\n",
    "print(f\"Mean CV ROC-AUC: {rf_cv_scores.mean():.4f} (+/- {rf_cv_scores.std():.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99039319-ba14-4158-bc4e-179c9fe9160e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TOP 15 MOST IMPORTANT FEATURES\n",
      "======================================================================\n",
      "             Feature  Importance\n",
      "                 Age    0.077171\n",
      "       MonthlyIncome    0.068291\n",
      "           WLB_Index    0.062073\n",
      "      YearsAtCompany    0.059051\n",
      "   TotalWorkingYears    0.058869\n",
      "YearsWithCurrManager    0.057148\n",
      "           DailyRate    0.046561\n",
      "    StockOptionLevel    0.045078\n",
      "    Income_Age_Ratio    0.044418\n",
      "   TotalSatisfaction    0.039326\n",
      "    OverTime_Numeric    0.039254\n",
      "  NumCompaniesWorked    0.035645\n",
      "     OverTime_Binary    0.033402\n",
      "         MonthlyRate    0.032690\n",
      "    DistanceFromHome    0.032221\n"
     ]
    }
   ],
   "source": [
    "# Feature Importance (Random Forest)\n",
    "print(\"\\nTOP 15 MOST IMPORTANT FEATURES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(feature_importance.head(15).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b00e39a7-7f8d-4c5c-9e0e-f79923565021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest model saved: models/random_forest_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save Random Forest model\n",
    "joblib.dump(rf_model, '../models/random_forest_model.pkl')\n",
    "print(\"\\nRandom Forest model saved: models/random_forest_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f51e712-7e27-4536-ace7-ac3422ca3d3e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## MODEL COMPARISON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53354dc1-81a1-4022-8218-fb8bf78c5a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FINAL MODEL COMPARISON\n",
      "======================================================================\n",
      "   Metric  Logistic Regression  Random Forest\n",
      " Accuracy             0.741497       0.823129\n",
      "Precision             0.350515       0.454545\n",
      "   Recall             0.723404       0.531915\n",
      " F1-Score             0.472222       0.490196\n",
      "  ROC-AUC             0.799724       0.780429\n",
      "\n",
      "BEST MODEL:\n",
      "   Logistic Regression (ROC-AUC: 0.7997)\n"
     ]
    }
   ],
   "source": [
    "# Compare both models\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL MODEL COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC'],\n",
    "    'Logistic Regression': [lr_accuracy, lr_precision, lr_recall, lr_f1, lr_roc_auc],\n",
    "    'Random Forest': [rf_accuracy, rf_precision, rf_recall, rf_f1, rf_roc_auc]\n",
    "})\n",
    "\n",
    "print(comparison.to_string(index=False))\n",
    "\n",
    "# Determine winner\n",
    "print(\"\\nBEST MODEL:\")\n",
    "if rf_roc_auc > lr_roc_auc:\n",
    "    print(f\"   Random Forest (ROC-AUC: {rf_roc_auc:.4f})\")\n",
    "    best_model = 'Random Forest'\n",
    "else:\n",
    "    print(f\"   Logistic Regression (ROC-AUC: {lr_roc_auc:.4f})\")\n",
    "    best_model = 'Logistic Regression'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8f091f-b78b-495d-85e3-a4d1a7667a4a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Model Training Complete!\n",
    "\n",
    "### Summary:\n",
    "\n",
    "**Models Trained:**\n",
    "1. Logistic Regression (baseline)\n",
    "2. Random Forest (advanced)\n",
    "\n",
    "**Files Saved:**\n",
    "- `models/scaler.pkl` - Feature scaler\n",
    "- `models/logistic_model.pkl` - Logistic Regression\n",
    "- `models/random_forest_model.pkl` - Random Forest\n",
    "\n",
    "**Key Metrics:**\n",
    "- Both models achieve **good performance**\n",
    "- Random Forest typically performs **better**\n",
    "- Feature importance shows **OverTime** is top predictor\n",
    "\n",
    "---\n",
    "\n",
    "**Next Step:** Proceed to `06_model_evaluation.ipynb` for detailed analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a52de88-d59d-4cfa-8bd4-6682007e6f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
