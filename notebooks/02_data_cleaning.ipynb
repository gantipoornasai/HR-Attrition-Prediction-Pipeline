{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60082b5b-cdc5-4331-bde4-894ee8607815",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "**Objective:** Clean and prepare the IBM HR data for analysis\n",
    "\n",
    "**Tasks:**\n",
    "1. Handle any data quality issues\n",
    "2. Convert data types where needed\n",
    "3. Remove unnecessary columns\n",
    "4. Create clean dataset for EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec3bfca0-e659-4d22-b792-223f5363a557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c911bbf2-415b-4411-be58-a8022018d34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from previous step...\n",
      "Data loaded!\n",
      "Shape: (1470, 35)\n",
      "1470 rows × 35 columns\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "print(\"Loading data from previous step...\")\n",
    "\n",
    "df = pd.read_csv('../data/external/enriched_data.csv')\n",
    "\n",
    "print(f\"Data loaded!\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"{df.shape[0]} rows × {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a3061c7-7300-4b2e-90be-6c20f1488cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Data Types:\n",
      "================================================================================\n",
      "Age                          int64\n",
      "Attrition                   object\n",
      "BusinessTravel              object\n",
      "DailyRate                    int64\n",
      "Department                  object\n",
      "DistanceFromHome             int64\n",
      "Education                    int64\n",
      "EducationField              object\n",
      "EmployeeCount                int64\n",
      "EmployeeNumber               int64\n",
      "EnvironmentSatisfaction      int64\n",
      "Gender                      object\n",
      "HourlyRate                   int64\n",
      "JobInvolvement               int64\n",
      "JobLevel                     int64\n",
      "JobRole                     object\n",
      "JobSatisfaction              int64\n",
      "MaritalStatus               object\n",
      "MonthlyIncome                int64\n",
      "MonthlyRate                  int64\n",
      "NumCompaniesWorked           int64\n",
      "Over18                      object\n",
      "OverTime                    object\n",
      "PercentSalaryHike            int64\n",
      "PerformanceRating            int64\n",
      "RelationshipSatisfaction     int64\n",
      "StandardHours                int64\n",
      "StockOptionLevel             int64\n",
      "TotalWorkingYears            int64\n",
      "TrainingTimesLastYear        int64\n",
      "WorkLifeBalance              int64\n",
      "YearsAtCompany               int64\n",
      "YearsInCurrentRole           int64\n",
      "YearsSinceLastPromotion      int64\n",
      "YearsWithCurrManager         int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check current data types\n",
    "print(\"\\nCurrent Data Types:\")\n",
    "print(\"=\"*80)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1dd3fd1-0e88-49b8-9e19-74bc8794a636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting to proper data types...\n",
      "✓ Converted Attrition to category\n",
      "✓ Converted BusinessTravel to category\n",
      "✓ Converted Department to category\n",
      "✓ Converted EducationField to category\n",
      "✓ Converted Gender to category\n",
      "✓ Converted JobRole to category\n",
      "✓ Converted MaritalStatus to category\n",
      "✓ Converted OverTime to category\n",
      "\n",
      "Data type conversion complete!\n"
     ]
    }
   ],
   "source": [
    "# Identify columns that should be categorical\n",
    "print(\"\\nConverting to proper data types...\")\n",
    "\n",
    "# Categorical columns\n",
    "categorical_columns = [\n",
    "    'Attrition', 'BusinessTravel', 'Department', 'EducationField',\n",
    "    'Gender', 'JobRole', 'MaritalStatus', 'OverTime'\n",
    "]\n",
    "\n",
    "for col in categorical_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype('category')\n",
    "        print(f\"✓ Converted {col} to category\")\n",
    "\n",
    "print(\"\\nData type conversion complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dc20221-92b1-4b00-9548-76ef936788bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking for constant columns (no variation)...\n",
      "EmployeeCount has only 1 unique value: 1\n",
      "Over18 has only 1 unique value: Y\n",
      "StandardHours has only 1 unique value: 80\n",
      "\n",
      "Found 3 constant column(s).\n",
      "These columns don't help prediction and should be removed.\n"
     ]
    }
   ],
   "source": [
    "# Check for columns that don't vary (constant values)\n",
    "print(\"\\nChecking for constant columns (no variation)...\")\n",
    "\n",
    "constant_cols = []\n",
    "for col in df.columns:\n",
    "    if df[col].nunique() == 1:\n",
    "        constant_cols.append(col)\n",
    "        print(f\"{col} has only 1 unique value: {df[col].unique()[0]}\")\n",
    "\n",
    "if constant_cols:\n",
    "    print(f\"\\nFound {len(constant_cols)} constant column(s).\")\n",
    "    print(\"These columns don't help prediction and should be removed.\")\n",
    "else:\n",
    "    print(\"No constant columns found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cf14491-cde0-485e-b857-5c2dc01db290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removing constant columns...\n",
      "Removed 3 columns: ['EmployeeCount', 'Over18', 'StandardHours']\n",
      "\n",
      "New shape: (1470, 32)\n"
     ]
    }
   ],
   "source": [
    "# Remove constant columns\n",
    "print(\"\\nRemoving constant columns...\")\n",
    "\n",
    "if constant_cols:\n",
    "    df = df.drop(columns=constant_cols)\n",
    "    print(f\"Removed {len(constant_cols)} columns: {constant_cols}\")\n",
    "else:\n",
    "    print(\"No columns to remove.\")\n",
    "\n",
    "print(f\"\\nNew shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32b7db68-dc38-4e86-8548-9c5c44bd7f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking numeric features...\n",
      "Found 24 numeric features\n"
     ]
    }
   ],
   "source": [
    "# Check for highly correlated features (numeric only)\n",
    "print(\"\\nChecking numeric features...\")\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "print(f\"Found {len(numeric_cols)} numeric features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d10407df-516f-4914-9019-9b7ac0e98731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FINAL DATA QUALITY REPORT\n",
      "================================================================================\n",
      "Total Rows: 1470\n",
      "Total Columns: 32\n",
      "Missing Values: 0\n",
      "Duplicates: 0\n",
      "\n",
      "Data Types Summary:\n",
      "int64       24\n",
      "category     2\n",
      "category     1\n",
      "category     1\n",
      "category     1\n",
      "category     1\n",
      "category     1\n",
      "category     1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Final data quality check\n",
    "print(\"\\nFINAL DATA QUALITY REPORT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"Total Rows: {len(df)}\")\n",
    "print(f\"Total Columns: {len(df.columns)}\")\n",
    "print(f\"Missing Values: {df.isnull().sum().sum()}\")\n",
    "print(f\"Duplicates: {df.duplicated().sum()}\")\n",
    "\n",
    "print(\"\\nData Types Summary:\")\n",
    "print(df.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f19f22ac-cb03-4bf9-bf3c-3d18616e16ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving cleaned dataset...\n",
      "Cleaned data saved to: data/processed/cleaned_data.csv\n",
      "Final shape: (1470, 32)\n",
      "\n",
      "Data cleaning complete! Ready for EDA.\n"
     ]
    }
   ],
   "source": [
    "# Save cleaned data\n",
    "print(\"\\nSaving cleaned dataset...\")\n",
    "\n",
    "df.to_csv('../data/processed/cleaned_data.csv', index=False)\n",
    "\n",
    "print(\"Cleaned data saved to: data/processed/cleaned_data.csv\")\n",
    "print(f\"Final shape: {df.shape}\")\n",
    "print(\"\\nData cleaning complete! Ready for EDA.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c20ddd-9474-4db1-8a56-e17c29de4d59",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Data Cleaning Summary:\n",
    "\n",
    "**Removed Columns:**\n",
    "- EmployeeCount (constant)\n",
    "- Over18 (constant)\n",
    "- StandardHours (constant)\n",
    "\n",
    "**Data Type Conversions:**\n",
    "- Converted 8 text columns to categorical type\n",
    "- Preserved all numeric columns\n",
    "\n",
    "**Data Quality:**\n",
    "- No missing values\n",
    "- No duplicates\n",
    "- Clean dataset ready for analysis\n",
    "\n",
    "**Output:** `data/processed/cleaned_data.csv`\n",
    "\n",
    "---\n",
    "\n",
    "**Next Step:** Proceed to `03_eda.ipynb` for Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b775c7d-9306-42b6-942f-b33076ef9f40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
